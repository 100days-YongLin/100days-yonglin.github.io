---
---

@inproceedings{10.1117/12.2637494,
author = {Gang Lin and Yanchun Liang and Yonglin Chen and Wenbo Pan},
title = {{Configurable image recognition framework design based on KNN and bit-based similarity model}},
volume = {12260},
booktitle = {International Conference on Computer Application and Information Security (ICCAIS 2021)},
editor = {Yingfa Lu and Changbo Cheng},
organization = {International Society for Optics and Photonics},
publisher = {SPIE},
pages = {122601I},
abstract = {CAPTCHAs are widely utilized on the Internet to partially protect against computer attacks, and text-based CAPTCHAs are commonly used. In order to make the more flexible attack, this paper provides a framework with configurable options based on k-NN, including three major parts: preprocessing the binary image, building standard library and recognizing image. The standard library is built from training dataset, where the third part can be an option to drop out some characters with a high similarity, and the library is used for testing dataset. A bit-based similarity model is proposed, where "and" and "or" bit operations are executed, and the result is the ratio of both operations. Finally, the framework is applied into four typical scenarios, MNIST handwriting database, CAPTCHAs built by the CAPTCHA generator, online CAPTCHAs of CNKI website, and CAPTCHAs within open source PHP DedeCMS, the average classification accuracy is 97.05%. As a result, the model is simple but effective, the framework can work well for text-based CAPTCHAs and handwritten numbers, which may make associated websites pay more attention to current authentication mechanism, and it offers flexibility to cover more algorithms and application scenarios by implementing different logics of preprocessing according to defined APIs.},
keywords = {CAPTCHAs, binary image recognition framework, KNN, bit-based similarity model},
year = {2022},
doi = {10.1117/12.2637494},
URL = {https://doi.org/10.1117/12.2637494},
selected={true},
pdf={122601I.pdf},
preview={preview1.jpg}
}


@ARTICLE{10673800,
  author={Zhang, Jingjing and Huang, Mengjie and Chen, Yonglin and Liao, Kai-Lun and Shi, Jiajia and Liang, Hai-Ning and Yang, Rui},
  journal={IEEE Transactions on Visualization and Computer Graphics}, 
  title={TouchMark: Partial Tactile Feedback Design for Upper Limb Rehabilitation in Virtual Reality}, 
  year={2024},
  volume={30},
  number={11},
  abstract = {The use of Virtual Reality (VR) technology, especially in medical rehabilitation, has expanded to include tactile cues along with visual stimuli. For patients with upper limb hemiplegia, tangible handles with haptic stimuli could improve their ability to perform daily activities. Traditional VR controllers are unsuitable for patient rehabilitation in VR, necessitating the design of specialized tangible handles with integrated tracking devices. Besides, matching tactile stimulation with corresponding virtual visuals could strengthen users' embodiment (i.e., owning and controlling virtual bodies) in VR, which is crucial for patients' training with virtual hands. Haptic stimuli have been shown to amplify the embodiment in VR, whereas the effect of partial tactile stimulation from tangible handles on embodiment remains to be clarified. This research, including three experiments, aims to investigate how partial tactile feedback of tangible handles impacts users' embodiment, and we proposed a design concept called TouchMark for partial tactile stimuli that could help users quickly connect the physical and virtual worlds. To evaluate users' tactile and comfort perceptions when grasping tangible handles in a non-VR setting, various handles with three partial tactile factors were manipulated in Study 1. In Study 2, we explored the effects of partial feedback using three forms of TouchMark on the embodiment of healthy users in VR, with various tangible handles, while Study 3 focused on similar investigations with patients. These handles were utilized to complete virtual food preparation tasks. The tactile and comfort perceptions of tangible handles and users' embodiment were evaluated in this research using questionnaires and interviews. The results indicate that TouchMark with haptic line and ring forms over no stimulation would significantly enhance users' embodiment, especially for patients. The low-cost and innovative TouchMark approach may assist users, particularly those with limited VR experience, in achieving the embodiment and enhancing their virtual interactive experience.},
  pages={7430-7440},
  keywords={Tactile sensors;Visualization;Training;Grasping;Thumb;Shape;Motors;Virtual rehabilitation;embodiment;body ownership;agency;self-location;tactile sensation},
  doi={10.1109/TVCG.2024.3456173},
  selected={true},
  pdf={TouchMark_Partial_Tactile_Feedback_Design_for_Upper_Limb_Rehabilitation_in_Virtual_Reality.pdf},
  preview={touchmark.jpg}}


@inproceedings{10536366,
  author={Zhang, Jingjing and Huang, Mengjie and Chen, Yonglin and Xue, Xiaoyi and Liao, Kai-Lun and Yang, Rui and Shi, Jiajia},
  booktitle={2024 IEEE Conference on Virtual Reality and 3D User Interfaces Abstracts and Workshops (VRW)}, 
  title={TacPoint: Influence of Partial Visuo-Tactile Feedback on Sense of Embodiment in Virtual Reality}, 
  year={2024},
  volume={},
  number={},
  abstract={The employment of Virtual Reality (VR) in medical rehabilitation has been broadened to incorporate visual and tactile feedback, while how people use tangible objects to induce better perceptions in VR remains unexplored. We investigated how partial visuotactile feedback influences users' embodiment and proposed a design idea named TacPoint (a red point mark) that connects to the physical and virtual worlds. The results reported that higher embodiment illusions could be induced in the TacPoint session than in others without feedback during virtual interactions. It is proposed that TacPoint could help people induce the embodiment easily to increase their positive experience in VR rehabilitation training.},
  pages={943-944},
  keywords={Human computer interaction;Training;Visualization;Three-dimensional displays;Design methodology;Conferences;Employment;Virtual reality;Embodiment;Body ownership;Agency;Self-location;Tactile sensation;Rehabilitation;H.1.2 [Human-centered computing]: Human-computer interaction (HCI) - HCI design and evaluation methods - User studies},
  doi={10.1109/VRW62533.2024.00268},
  selected={true},
  pdf={TacPoint_Influence_of_Partial_Visuo-Tactile_Feedback_on_Sense_of_Embodiment_in_Virtual_Reality.pdf},
  preview={touchpos.jpg}}

@inproceedings{10.1145/3708359.3712142,
author = {Cao, Yancheng and He, Yangyang and Chen, Yonglin and Chen, Menghan and You, Shanhe and Qiu, Yulin and Liu, Min and Luo, Chuan and Zheng, Chen and Tong, Xin and Liang, Jing and Gong, Jiangtao},
title = {Designing LLM-simulated Immersive Spaces to Enhance Autistic Children's Social Affordances Understanding in Traffic Settings},
year = {2025},
isbn = {9798400713064},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3708359.3712142},
doi = {10.1145/3708359.3712142},
abstract = {One of the key challenges faced by autistic children is understanding social affordances in complex environments, which further impacts their ability to respond appropriately to social signals. In traffic scenarios, this impairment can even lead to safety concerns. In this paper, we introduce an LLM-simulated immersive projection environment designed to improve this ability in autistic children while ensuring their safety. We first propose 17 design considerations across four major categories, derived from a comprehensive review of previous research. Next, we developed a system called AIRoad, which leverages LLMs to simulate drivers with varying social intents, expressed through explicit multimodal social signals. AIRoad helps autistic children bridge the gap in recognizing the intentions behind behaviors and learning appropriate responses through various stimuli. A user study involving 14 participants demonstrated that this technology effectively engages autistic children and leads to significant improvements in their comprehension of social affordances in traffic scenarios. Additionally, parents reported high perceived usability of the system. These findings highlight the potential of combining LLM technology with immersive environments for the functional rehabilitation of autistic children in the future.},
booktitle = {Proceedings of the 30th International Conference on Intelligent User Interfaces},
pages = {519â€“537},
numpages = {19},
keywords = {autistic children, LLM, immersive environment, social affordances, traffic settings},
location = {
},
series = {IUI '25},
preview = {cave_preview.png},
pdf = {Designing LLM-simulated Immersive Spaces.pdf},
selected={true},
}

